{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import nb_002\n",
    "from nb_002c import *\n",
    "\n",
    "import operator\n",
    "from random import sample\n",
    "from torch.utils.data.sampler import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "PATH = DATA_PATH/'caltech101' # http://www.vision.caltech.edu/Image_Datasets/Caltech101/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caltech 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FilesDataset(Dataset):\n",
    "    def __init__(self, fns, labels, classes=None):\n",
    "        if classes is None: classes = list(set(labels))\n",
    "        self.classes = classes\n",
    "        self.class2idx = {v:k for k,v in enumerate(classes)}\n",
    "        self.fns = np.array(fns)\n",
    "        self.y = [self.class2idx[o] for o in labels]\n",
    "        \n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i): return open_image(self.fns[i]),self.y[i]\n",
    "    \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, classes=None, test_pct=0.):\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "            \n",
    "        fns,labels = [],[]\n",
    "        for cl in classes:\n",
    "            fnames = get_image_files(folder/cl)\n",
    "            fns += fnames\n",
    "            labels += [cl] * len(fnames)\n",
    "            \n",
    "        if test_pct==0.: return cls(fns, labels, classes=classes)\n",
    "        \n",
    "        fns,labels = np.array(fns),np.array(labels)\n",
    "        is_test = np.random.uniform(size=(len(fns),)) < test_pct\n",
    "        return (cls(fns[~is_test], labels[~is_test], classes=classes),\n",
    "                cls(fns[is_test], labels[is_test], classes=classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplanes\", \"Motorbikes\", \"BACKGROUND_Google\", \"Faces\", \"watch\", \"Leopards\", \"bonsai\",\n",
    "    \"car_side\", \"ketch\", \"chandelier\", \"hawksbill\", \"grand_piano\", \"brain\", \"butterfly\", \"helicopter\", \"menorah\",\n",
    "    \"trilobite\", \"starfish\", \"kangaroo\", \"sunflower\", \"ewer\", \"buddha\", \"scorpion\", \"revolver\", \"laptop\", \"ibis\", \"llama\",\n",
    "    \"minaret\", \"umbrella\", \"electric_guitar\", \"crab\", \"crayfish\",]\n",
    "\n",
    "np.random.seed(42)\n",
    "train_ds,valid_ds = FilesDataset.from_folder(PATH, test_pct=0.2)\n",
    "\n",
    "x = train_ds[1114][0]\n",
    "classes = train_ds.classes\n",
    "c = len(classes)\n",
    "\n",
    "len(train_ds),len(valid_ds),c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangular affine fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(x, figsize=(6,3), hide_axis=False)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_m = np.array(rotate(40.)); rot_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(rot_m)(x), figsize=(6,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def affine_grid(x, matrix, size=None):\n",
    "    h,w = x.shape[1:]\n",
    "    if size is None: size=x.shape\n",
    "    matrix[0,1] *= h/w; matrix[1,0] *= w/h\n",
    "    return F.affine_grid(matrix[None,:2], torch.Size((1,)+size))\n",
    "\n",
    "nb_002.affine_grid = affine_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_affine(rot_m)(x), figsize=(6,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop with padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TfmType = IntEnum('TfmType', 'Start Affine Coord Pixel Lighting Crop')\n",
    "\n",
    "@reg_transform\n",
    "def crop_pad(x, size, padding_mode='reflect',\n",
    "             row_pct:uniform = 0.5, col_pct:uniform = 0.5) -> TfmType.Crop:\n",
    "    size = listify(size,2)\n",
    "    rows,cols = size\n",
    "    if x.size(1)<rows or x.size(2)<cols:\n",
    "        row_pad = max((rows-x.size(1)+1)//2, 0)\n",
    "        col_pad = max((cols-x.size(2)+1)//2, 0)\n",
    "        x = F.pad(x[None], (col_pad,col_pad,row_pad,row_pad), mode=padding_mode)[0]\n",
    "    row = int((x.size(1)-rows+1)*row_pct)\n",
    "    col = int((x.size(2)-cols+1)*col_pct)\n",
    "\n",
    "    x = x[:, row:row+rows, col:col+cols]\n",
    "    return x.contiguous() # without this, get NaN later - don't know why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(crop_pad(x, 300, row_pct=0.,col_pct=0., padding_mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(crop_pad(x, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(crop_pad(x, 150, row_pct=0.,col_pct=0.98, padding_mode='constant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = crop_pad_tfm(row_pct=(0,1.), col_pct=(0,1.))\n",
    "\n",
    "_,axes = plt.subplots(1,4, figsize=(12,3))\n",
    "for ax in axes.flat: show_image(tfm()(x, size=150), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine crop/resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def round_multiple(x, mult): return (int(x/mult+0.5)*mult)\n",
    "\n",
    "def get_crop_target(target_px, target_aspect=1., mult=32):\n",
    "    target_px = listify(target_px, 2)\n",
    "    target_r = math.sqrt(target_px[0]*target_px[1]/target_aspect)\n",
    "    target_c = target_r*target_aspect\n",
    "    return round_multiple(target_r,mult),round_multiple(target_c,mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_crop_target(220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_target = get_crop_target(220, 2.);\n",
    "target_r,target_c = crop_target\n",
    "crop_target, target_r*target_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,r,c = x.shape; x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_ratio = r/target_r\n",
    "c_ratio = c/target_c\n",
    "# min -> crop; max -> pad\n",
    "ratio = max(r_ratio,c_ratio)\n",
    "r_ratio,c_ratio,ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2,c2 = round(r/ratio),round(c/ratio); r2,c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_resize_target(img, crop_target, do_crop=False):\n",
    "    if crop_target is None: return None\n",
    "    ch,r,c = img.shape\n",
    "    target_r,target_c = crop_target\n",
    "    ratio = (min if do_crop else max)(r/target_r, c/target_c)\n",
    "    return ch,round(r/ratio),round(c/ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_resize_target(x, crop_target, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_resize_target(x, crop_target, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _apply_affine(img, size=None, padding_mode='reflect', do_crop=False, aspect=None, mult=32,\n",
    "                  m=None, func=None, crop_func=None, **kwargs):\n",
    "    if size is not None and not isinstance(size, (tuple,list)):\n",
    "        size = listify(size,2) if aspect is None else get_crop_target(size, aspect, mult)\n",
    "    if m is None and func is None and size is None: return img\n",
    "    resize_target = get_resize_target(img, size, do_crop=do_crop)\n",
    "    c = affine_grid(img, torch.eye(3), size=resize_target)\n",
    "    if func is not None: c = func(c, img.size())\n",
    "    if m is not None: c = affine_mult(c, img.new_tensor(m))\n",
    "    res = grid_sample(img, c, padding_mode=padding_mode, **kwargs)\n",
    "    if padding_mode=='zeros': padding_mode='constant'\n",
    "    if crop_func is not None: res = crop_func(res, size=size, padding_mode=padding_mode)\n",
    "    return res\n",
    "\n",
    "def apply_affine(m=None, func=None, crop_func=None):\n",
    "    return partial(_apply_affine, m=m, func=func, crop_func=crop_func)\n",
    "\n",
    "nb_002.apply_affine = apply_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def affines_mat(matrices=None):\n",
    "    if matrices is None or len(matrices) == 0: return None#Chaning here to return None instead of identity\n",
    "    matrices = [FloatTensor(m) for m in matrices if m is not None]\n",
    "    return reduce(torch.matmul, matrices, torch.eye(3))\n",
    "\n",
    "nb_002.affines_mat = affines_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m)(x, size=crop_target, do_crop=False)\n",
    "show_image(img, figsize=(6,3))\n",
    "crop_target, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_crop_target(160,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m)(x, size=160, aspect=2, do_crop=True)\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m, crop_func=crop_pad)(x, do_crop=False, size=crop_target)\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m, crop_func=crop_pad)(x, do_crop=False, size=crop_target, padding_mode='zeros')\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = apply_affine(rot_m, crop_func=crop_pad)(x, do_crop=True, size=crop_target)\n",
    "show_image(img, figsize=(6,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_002 import _apply_tfm_funcs\n",
    "\n",
    "def apply_tfms(tfms):\n",
    "    grouped_tfms = dict_groupby(listify(tfms), lambda o: o.tfm_type)\n",
    "    start_tfms,affine_tfms,coord_tfms,pixel_tfms,lighting_tfms,crop_tfms = [\n",
    "        resolve_tfms(grouped_tfms.get(o)) for o in TfmType]\n",
    "    lighting_func = apply_lighting(compose(lighting_tfms))\n",
    "    affine_func = apply_affine(\n",
    "        affines_mat(affine_tfms), func=compose(coord_tfms) if len(coord_tfms) != 0 else None, crop_func=compose(crop_tfms))\n",
    "    return partial(_apply_tfm_funcs,\n",
    "        compose(pixel_tfms),lighting_func,affine_func,compose(start_tfms))\n",
    "\n",
    "nb_002.apply_tfms = apply_tfms\n",
    "import nb_002b\n",
    "nb_002b.apply_tfms = apply_tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [\n",
    "    rotate_tfm(degrees=(-20,20.)),\n",
    "    zoom_tfm(scale=(1.,1.95)),\n",
    "]\n",
    "\n",
    "_,axes = plt.subplots(2,2, figsize=(7,5))\n",
    "for ax in axes.flat:\n",
    "    show_image(apply_tfms(tfms)(x, do_crop=True, size=(60,100)), ax, hide_axis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [\n",
    "    rotate_tfm(degrees=(-20,20.)),\n",
    "    zoom_tfm(scale=(1.,1.95), row_pct=(0,1), col_pct=(0,1)),\n",
    "    crop_pad_tfm(row_pct=(0,1), col_pct=(0,1))\n",
    "]\n",
    "\n",
    "_,axes = plt.subplots(2,2, figsize=(6,6))\n",
    "for ax in axes.flat:\n",
    "    show_image(apply_tfms(tfms)(x, do_crop=False, size=100, padding_mode='zeros'), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [crop_tfm(size=100)]\n",
    "_,axes = plt.subplots(1,4, figsize=(9,3))\n",
    "for ax in axes.flat: show_image(apply_tfms(tfms)(x, do_crop=True), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [crop_tfm(size=100, row_pct=(0,1), col_pct=(0,1))]\n",
    "_,axes = plt.subplots(1,4, figsize=(9,3))\n",
    "for ax in axes.flat: show_image(apply_tfms(tfms)(x, do_crop=True), ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[Image.open(fn).size for fn in np.random.choice(train_ds.fns, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = [\n",
    "    rotate_tfm(degrees=(-20,20.)),\n",
    "    zoom_tfm(scale=(1.,1.5), row_pct=(0,1.), col_pct=(0,1.)),\n",
    "    crop_pad_tfm(row_pct=(0,1.), col_pct=(0,1.))\n",
    "]\n",
    "valid_tfms = [\n",
    "    zoom_tfm(),\n",
    "    crop_pad_tfm()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(1,4, figsize=(10,5))\n",
    "for ax in axes.flat:\n",
    "    show_image(apply_tfms(train_tfms)(x, do_crop=True, size=size), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(apply_tfms(valid_tfms)(x, do_crop=True, size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tds = TfmDataset(valid_ds, valid_tfms, size=150, padding_mode='zeros')\n",
    "data = DataBunch(valid_tds, valid_tds, bs=bs, num_workers=0)\n",
    "xb,yb = next(iter(data.train_dl))\n",
    "b = xb.transpose(1,0).reshape(3,-1)\n",
    "data_mean=b.mean(1).cpu()\n",
    "data_std=b.std(1).cpu()\n",
    "data_mean,data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_batch(data.train_dl, train_ds.classes, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_tfm = normalize_tfm(mean=data_mean, std=data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_tds = TfmDataset(valid_ds, valid_tfms+[norm_tfm], size=150, padding_mode='zeros')\n",
    "train_tds = TfmDataset(train_ds, train_tfms+[norm_tfm], size=150, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_tds, valid_tds, bs=bs, num_workers=12)\n",
    "len(data.train_dl),len(data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 4, 4, 2], num_classes=c, nf=16)\n",
    "learn = Learner(data, model)\n",
    "opt_fn = partial(optim.SGD, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1, 0.1, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(1, 0.2, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(5, 0.4, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.fit(5, 0.1, opt_fn=opt_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
