{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_002 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "PATH = DATA_PATH/'caltech101'\n",
    "fPATH = DATA_PATH/'cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class FilesDataset(Dataset):\n",
    "    def __init__(self, fns, labels, classes=None, tfms=None):\n",
    "        if classes is None: classes = list(set(labels))\n",
    "        self.classes,self.tfms = classes,torchvision.transforms.Compose(tfms)\n",
    "        self.class2idx = {v:k for k,v in enumerate(classes)}\n",
    "        self.fns = np.array(fns)\n",
    "        self.y = [self.class2idx[o] for o in labels]\n",
    "        \n",
    "    @classmethod\n",
    "    def from_folder(cls, folder, classes=None, test_pct=0., tfms=None):\n",
    "        if classes is None: classes = [cls.name for cls in find_classes(folder)]\n",
    "            \n",
    "        fns,labels = [],[]\n",
    "        for cl in classes:\n",
    "            fnames = get_image_files(folder/cl)\n",
    "            fns += fnames\n",
    "            labels += [cl] * len(fnames)\n",
    "            \n",
    "        if test_pct==0.: return cls(fns, labels)\n",
    "        fns,labels = np.array(fns),np.array(labels)\n",
    "        is_test = np.random.uniform(size=(len(fns),)) < test_pct\n",
    "        return cls(fns[~is_test], labels[~is_test], tfms=tfms[0]), cls(fns[is_test], labels[is_test], tfms=tfms[1])\n",
    "\n",
    "    def __len__(self): return len(self.fns)\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        x = PIL.Image.open(self.fns[i]).convert('RGB')\n",
    "        x = self.tfms(x)\n",
    "        return pil2tensor(x),self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 224\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_tfms = [torchvision.transforms.RandomResizedCrop(sz, scale=(0.5, 1.0)),\n",
    "             torchvision.transforms.RandomHorizontalFlip()] #torchvision.transforms.RandomRotation(10),\n",
    "val_tfms = [torchvision.transforms.Resize(sz),\n",
    "            torchvision.transforms.CenterCrop(sz)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplanes','Motorbikes','Faces','watch','Leopards']\n",
    "np.random.seed(42)\n",
    "train_ds,valid_ds = FilesDataset.from_folder(PATH, classes=classes, test_pct=0.2, tfms=(trn_tfms,val_tfms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, means2 = torch.zeros(3),torch.zeros(3)\n",
    "counts = 0\n",
    "for i in tqdm(range(len(train_ds))):\n",
    "    x = PIL.Image.open(train_ds.fns[i]).convert('RGB')\n",
    "    x = pil2tensor(x)\n",
    "    means += x.reshape(3,-1).sum(1)\n",
    "    means2 += x.pow(2).reshape(3,-1).sum(1)\n",
    "    counts += x.reshape(3,-1).size(1)\n",
    "for i in tqdm(range(len(valid_ds))):\n",
    "    x = PIL.Image.open(train_ds.fns[i]).convert('RGB')\n",
    "    x = pil2tensor(x)\n",
    "    means += x.reshape(3,-1).sum(1)\n",
    "    means2 += x.pow(2).reshape(3,-1).sum(1)\n",
    "    counts += x.reshape(3,-1).size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means/counts, torch.sqrt(means2/counts - (means/counts)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = (np.array([0.5355,0.5430,0.5280]), np.array([0.2909,0.2788,0.2979]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for xb, yb in self.dl:\n",
    "            xb,yb = xb.to(self.device),yb.to(self.device)\n",
    "            xb.add_(-1, self.m[None,:,None,None]).div_(self.s[None,:,None,None])\n",
    "            yield xb,yb\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(ds, bs, shuffle, cuda_id, stats, sampler):\n",
    "    device = torch.device('cuda', cuda_id)\n",
    "    dl = DataLoader1(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True)\n",
    "    return DeviceDataLoader(dl, device, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader as DataLoader1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, trn_ds, val_ds, stats, cuda_id, trn_sampler=None, val_sampler=None, bs=64):\n",
    "        if hasattr(trn_ds, 'classes'): self.classes = trn_ds.classes\n",
    "        self.device = torch.device('cuda', cuda_id)\n",
    "        self.trn_dl = get_dataloader(trn_ds, bs, shuffle=(trn_sampler is None), cuda_id=cuda_id, stats=stats, sampler=trn_sampler)\n",
    "        self.val_dl = get_dataloader(val_ds, bs*2, shuffle=False, cuda_id=cuda_id, stats=stats, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(train_ds, valid_ds, stats, 0, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(ni, nf, ks=3, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, kernel_size=ks, bias=False, stride=stride, padding=ks//2),\n",
    "        nn.BatchNorm2d(nf),\n",
    "        nn.LeakyReLU(negative_slope=0.1, inplace=True))\n",
    "\n",
    "class ResLayer(nn.Module):\n",
    "    def __init__(self, ni):\n",
    "        super().__init__()\n",
    "        self.conv1=conv_layer(ni, ni//2, ks=1)\n",
    "        self.conv2=conv_layer(ni//2, ni, ks=3)\n",
    "        \n",
    "    def forward(self, x): return x + self.conv2(self.conv1(x))\n",
    "\n",
    "class Darknet(nn.Module):\n",
    "    def make_group_layer(self, ch_in, num_blocks, stride=1):\n",
    "        return [conv_layer(ch_in, ch_in*2,stride=stride)\n",
    "               ] + [(ResLayer(ch_in*2)) for i in range(num_blocks)]\n",
    "\n",
    "    def __init__(self, num_blocks, num_classes, nf=32):\n",
    "        super().__init__()\n",
    "        layers = [conv_layer(3, nf, ks=3, stride=1)]\n",
    "        for i,nb in enumerate(num_blocks):\n",
    "            layers += self.make_group_layer(nf, nb, stride=2-(i==1))\n",
    "            nf *= 2\n",
    "        layers += [nn.AdaptiveAvgPool2d(1), Flatten(), nn.Linear(nf, num_classes)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x): return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Darknet([1, 2, 4, 6, 3], num_classes=len(classes), nf=16).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "fdata = ImageClassifierData.from_paths(fPATH, val_name='test', tfms=ftfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.95,0.99))\n",
    "learner = Learner.from_model_data(model, fdata, opt_fn=opt_fn)\n",
    "learner.data.trn_dl, learner.data.val_dl = data.trn_dl, data.val_dl\n",
    "learner.crit = F.cross_entropy\n",
    "learner.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.trn_dl.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(2e-3, 1, cycle_len=30, wds=0.1, use_wd_sched=True, use_clr_beta=(10,10,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x.numpy().transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader1():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = dl,device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for xb, yb in self.dl:\n",
    "            xb.add_(-1, self.m[None,:,None,None]).div_(self.s[None,:,None,None])\n",
    "            yield xb,yb\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader1():\n",
    "    def __init__(self, dl, device, stats):\n",
    "        self.dl,self.device = DataPrefetcher(dl),device\n",
    "        self.m, self.s = map(lambda x:torch.tensor(x, dtype=torch.float32, device=device), stats)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for xb, yb in self.dl:\n",
    "            xb.add_(-1, self.m[None,:,None,None]).div_(self.s[None,:,None,None])\n",
    "            yield xb,yb\n",
    "    \n",
    "    def __len__(self): return (len(self.dl))\n",
    "\n",
    "class DataBunch():\n",
    "    def __init__(self, trn_ds, val_ds, stats, cuda_id, trn_sampler=None, val_sampler=None, bs=64):\n",
    "        if hasattr(trn_ds, 'classes'): self.classes = trn_ds.classes\n",
    "        self.trn_dl = get_dataloader(trn_ds, bs, shuffle=(trn_sampler is None), cuda_id=cuda_id, stats=stats, sampler=trn_sampler)\n",
    "        self.val_dl = get_dataloader(val_ds, bs*2, shuffle=False, cuda_id=cuda_id, stats=stats, sampler=val_sampler)\n",
    "\n",
    "    @classmethod\n",
    "    def from_files(cls, Path, trn_tfms, val_tfms, stats, sz, cuda_id, distrib=False, logs=None, trn_name='train', val_name='valid', bs=64):\n",
    "        trn_ds, val_ds = TransformedFilesDataset(Path/trn_name, sz, trn_tfms), ValTransformedFilesDataset(Path/val_name, sz, val_tfms)\n",
    "        trn_sampler = DistributedSampler(trn_ds) if distrib else None\n",
    "        val_sampler = None #DistributedSampler(val_ds) if distrib else None\n",
    "        return cls(trn_ds, val_ds, stats, cuda_id, trn_sampler, val_sampler, bs)\n",
    "\n",
    "def init_np(id):\n",
    "    seed = (torch.initial_seed() + id) % (2**32)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def get_dataloader(ds, bs, shuffle, cuda_id, stats, sampler):\n",
    "    device = torch.device('cuda', cuda_id)\n",
    "    dl = DataLoader1(ds, batch_size=bs, shuffle=shuffle,num_workers=8, sampler=sampler, pin_memory=True, worker_init_fn=init_np)\n",
    "    return DeviceDataLoader1(dl, device, stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
