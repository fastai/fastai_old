{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nb_004c import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs and cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../../data/dogscats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean, data_std = map(tensor, ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "data_norm,data_denorm = normalize_funcs(data_mean,data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FilesDataset.from_folder(PATH/'train')\n",
    "valid_ds = FilesDataset.from_folder(PATH/'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Image(valid_ds[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def uniform_int(low, high, size=None):\n",
    "    return random.randint(low,high) if size is None else torch.randint(low,high,size)\n",
    "\n",
    "@TfmPixel\n",
    "def dihedral(x, k:partial(uniform_int,0,8)):\n",
    "    flips=[]\n",
    "    if k&1: flips.append(1)\n",
    "    if k&2: flips.append(2)\n",
    "    if flips: x = torch.flip(x,flips)\n",
    "    if k&4: x = x.transpose(1,2)\n",
    "    return x.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axes = plt.subplots(2,4, figsize=(12,6))\n",
    "for i,ax in enumerate(axes.flat): dihedral(x,i).show(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_transforms(do_flip=False, flip_vert=False, max_rotate=0., max_zoom=1., max_lighting=0., max_warp=0.,\n",
    "                   p_affine=0.75, p_lighting=0.5, xtra_tfms=None):\n",
    "    res = [rand_crop()]\n",
    "    if do_flip:    res.append(dihedral() if flip_vert else flip_lr(p=0.5))\n",
    "    if max_warp:   res.append(symmetric_warp(magnitude=(-max_warp,max_warp), p=p_affine))\n",
    "    if max_rotate: res.append(rotate(degrees=(-max_rotate,max_rotate), p=p_affine))\n",
    "    if max_zoom>1: res.append(rand_zoom(scale=(1.,max_zoom), p=p_affine))\n",
    "    if max_lighting:\n",
    "        res.append(brightness(change=(0.5*(1-max_lighting), 0.5*(1+max_lighting)), p=p_lighting))\n",
    "        res.append(contrast(scale=(1-max_lighting, 1/(1-max_lighting)), p=p_lighting))\n",
    "    #       train                   , valid\n",
    "    return (res + listify(xtra_tfms), [crop_pad()])  \n",
    "\n",
    "def transform_datasets(train_ds, valid_ds, tfms, size=None):\n",
    "    return (DatasetTfm(train_ds, tfms[0], size=size),\n",
    "            DatasetTfm(valid_ds, tfms[1], size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = get_transforms(do_flip=True, max_rotate=10, max_zoom=1.25, max_lighting=0.4, max_warp=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=224\n",
    "tds = transform_datasets(train_ds, valid_ds, tfms, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch(*tds, bs=64, num_workers=8, tfms=data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = next(iter(data.valid_dl))\n",
    "\n",
    "_,axs = plt.subplots(4,4,figsize=(12,12))\n",
    "for i,ax in enumerate(axs.flatten()): show_image(data_denorm(x[i].cpu()), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(4,4,figsize=(12,12))\n",
    "for ax in axs.flat: show_image(tds[0][1][0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet34\n",
    "arch = resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = arch()\n",
    "learn = Learner(data, model, wd=1e-2)\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fit_one_cycle(learn, 1e-3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with a new head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, sz=None):\n",
    "        super().__init__()\n",
    "        sz = sz or 1\n",
    "        self.ap,self.mp = nn.AdaptiveAvgPool2d(sz), nn.AdaptiveMaxPool2d(sz)\n",
    "    def forward(self, x): return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "def create_skeleton(model, cut):\n",
    "    layers = list(model.children())[:-cut] if cut else [model]\n",
    "    layers += [AdaptiveConcatPool2d(), Flatten()]\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def num_features(m):\n",
    "    c=list(m.children())\n",
    "    if len(c)==0: return None\n",
    "    for l in reversed(c):\n",
    "        if hasattr(l, 'num_features'): return l.num_features\n",
    "        res = num_features(l)\n",
    "        if res is not None: return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_skeleton(arch(), 2)\n",
    "num_features(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bn_dp_lin(n_in, n_out, bn=True, dp=0., actn=None):\n",
    "    layers = [nn.BatchNorm1d(n_in)] if bn else []\n",
    "    if dp != 0: layers.append(nn.Dropout(dp))\n",
    "    layers.append(nn.Linear(n_in, n_out))\n",
    "    if actn is not None: layers.append(actn)\n",
    "    return layers\n",
    "\n",
    "def create_head(nf, nc, lin_ftrs=None, dps=None):\n",
    "    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    if dps is None: dps = [0.25] * (len(lin_ftrs)-2) + [0.5]\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    for ni,no,dp,actn in zip(lin_ftrs[:-1],lin_ftrs[1:],dps,actns): \n",
    "        layers += bn_dp_lin(ni,no,True,dp,actn)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class ConvLearner(Learner):\n",
    "    def __init__(self, data, arch, cut, pretrained=True, lin_ftrs=None, dps=None, **kwargs):\n",
    "        self.skeleton = create_skeleton(arch(pretrained), cut)\n",
    "        nf = num_features(self.skeleton) * 2\n",
    "        # XXX: better way to get num classes\n",
    "        self.head = create_head(nf, len(data.train_ds.ds.classes), lin_ftrs, dps)\n",
    "        model = nn.Sequential(self.skeleton, self.head)\n",
    "        super().__init__(data, model, **kwargs)\n",
    "    \n",
    "    def freeze(self):\n",
    "        for p in self.skeleton.parameters(): p.requires_grad = False\n",
    "    \n",
    "    def unfreeze(self):\n",
    "        for p in self.skeleton.parameters(): p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_head(512, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, arch, 2, wd=1e-3)\n",
    "learn.metrics = [accuracy]\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(3, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_cycle(learn, 3e-4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradual unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLearner(Learner):\n",
    "    def __init__(self, data, arch, cut, pretrained=True, lin_ftrs=None, dps=None, **kwargs):\n",
    "        self.skeleton = create_skeleton(arch(pretrained), cut)\n",
    "        nf = num_features(self.skeleton) * 2\n",
    "        # XXX: better way to get num classes\n",
    "        self.head = create_head(nf, len(data.train_ds.ds.classes), lin_ftrs, dps)\n",
    "        model = nn.Sequential(self.skeleton, self.head)\n",
    "        super().__init__(data, model, **kwargs)\n",
    "    \n",
    "    def freeze_to(self, n):\n",
    "        for g in self.layer_groups[:n]: \n",
    "            for p in g.parameters(): p.requires_grad = False\n",
    "        for g in self.layer_groups[n:]:\n",
    "            for p in g.parameters(): p.requires_grad = True\n",
    "            \n",
    "    def freeze(self): self.freeze_to(len(self.layer_groups))\n",
    "    def unfreeze(self): self.freeze_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, arch, 2, wd=1e-3)\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.split(lambda m: (m[0][6], m[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([1e-3/25,1e-3/5,1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fit_one_cycle(learn, lrs/4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time fit_one_cycle(learn, lrs/8, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_datasets(train_ds, valid_ds, tfms, size=None):\n",
    "    return (DatasetTfm(train_ds, tfms[0], size=size),\n",
    "            DatasetTfm(valid_ds, tfms[1], size=size),\n",
    "            DatasetTfm(valid_ds, tfms[0], size=size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataBunch():\n",
    "    def __init__(self, train_ds, valid_ds, augm_ds, bs=64, device=None, num_workers=4, **kwargs):\n",
    "        self.device = default_device if device is None else device\n",
    "        self.train_dl = DeviceDataLoader.create(train_ds, bs,   shuffle=True,  num_workers=num_workers, **kwargs)\n",
    "        self.valid_dl = DeviceDataLoader.create(valid_ds, bs*2, shuffle=False, num_workers=num_workers, **kwargs)\n",
    "        self.augm_dl  = DeviceDataLoader.create(augm_ds,  bs*2, shuffle=False, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, train_tfm=None, valid_tfm=None, dl_tfms=None, **kwargs):\n",
    "        return cls(DatasetTfm(train_ds, train_tfm), DatasetTfm(valid_ds, valid_tfm), DatasetTfm(valid_ds, train_tfm), \n",
    "                   tfms=dl_tfms, **kwargs)\n",
    "\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dl.dataset\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = transform_datasets(train_ds, valid_ds, tfms, size=size)\n",
    "data = DataBunch(*tds, num_workers=8, tfms=data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, arch, 2, wd=1e-3)\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(2,4,figsize=(12,6))\n",
    "for ax in axs.flat: show_image(tds[2][1][0], ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.model\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds,y = zip(*[(model(xb.detach()), yb.detach()) for xb,yb in data.valid_dl])\n",
    "\n",
    "preds = torch.cat(preds)\n",
    "y = torch.cat(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, dl):\n",
    "    with torch.no_grad():\n",
    "        return torch.cat([model(xb.detach()) for xb,yb in dl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = torch.stack([get_preds(model, data.augm_dl) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(0)\n",
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(avg_preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for beta in (0.01,0.2,0.4,0.5,0.6,0.8,0.99):\n",
    "    print(accuracy(preds*beta + avg_preds*(1-beta), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
