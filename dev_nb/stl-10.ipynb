{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_005 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STL-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/stl10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mean, data_std = map(tensor, ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]))\n",
    "data_norm,data_denorm = normalize_funcs(data_mean,data_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = FilesDataset.from_folder(PATH/'train')\n",
    "valid_ds = FilesDataset.from_folder(PATH/'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Image(valid_ds[0][0])\n",
    "x.show()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_datasets(train_ds, valid_ds, tfms, **kwargs):\n",
    "    return (DatasetTfm(train_ds, tfms[0], **kwargs),\n",
    "            DatasetTfm(valid_ds, tfms[1], **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=96\n",
    "tfms = get_transforms(do_flip=True, max_rotate=5, max_lighting=0.2, max_warp=0.15)#, max_zoom=1.25)\n",
    "# tfms = get_transforms(do_flip=True)#, max_rotate=5, max_lighting=0.1)\n",
    "tds = transform_datasets(train_ds, valid_ds, tfms, size=size, padding_mode='zeros')\n",
    "data = DataBunch(*tds, bs=32, num_workers=8, tfms=data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = next(iter(data.valid_dl))\n",
    "\n",
    "_,axs = plt.subplots(4,4,figsize=(12,12))\n",
    "for i,ax in enumerate(axs.flatten()): show_image(data_denorm(x[i].cpu()), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = next(iter(data.train_dl))\n",
    "\n",
    "_,axs = plt.subplots(4,4,figsize=(12,12))\n",
    "for i,ax in enumerate(axs.flatten()): show_image(data_denorm(x[i].cpu()), ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(4,4,figsize=(12,12))\n",
    "for i,ax in enumerate(axs.flat): show_image(tds[0][1][0], ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "arch = resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bn_eval(m):\n",
    "    for l in m.children():\n",
    "        if isinstance(l, bn_types) and not next(l.parameters()).requires_grad:\n",
    "            l.eval()\n",
    "        set_bn_eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bn_eval(m):\n",
    "    for l in m.children():\n",
    "        set_bn_eval(l)\n",
    "        if isinstance(l, bn_types):\n",
    "            l.momentum = 0.01 if next(l.parameters()).requires_grad else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BnFreeze(Callback):\n",
    "    learn:Learner\n",
    "    def on_train_begin(self, **kwargs): set_bn_eval(self.learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLearner(Learner):\n",
    "    def __init__(self, data, arch, cut, pretrained=True, lin_ftrs=None, dps=None, **kwargs):\n",
    "        skeleton = create_skeleton(arch(pretrained), cut)\n",
    "        nf = num_features(skeleton) * 2\n",
    "        # XXX: better way to get num classes\n",
    "        head = create_head(nf, len(data.train_ds.ds.classes), lin_ftrs, dps)\n",
    "        model = nn.Sequential(skeleton, head)\n",
    "        super().__init__(data, model, **kwargs)\n",
    "        self.split(lambda m: (m[1],))\n",
    "\n",
    "    def freeze_to(self, n):\n",
    "        for g in self.layer_groups[:n]:\n",
    "            for p in g.parameters(): p.requires_grad = False\n",
    "        for g in self.layer_groups[n:]:\n",
    "            for p in g.parameters(): p.requires_grad = True\n",
    "\n",
    "    def freeze(self):\n",
    "        assert(len(self.layer_groups)>1)\n",
    "        self.freeze_to(-1)\n",
    "        \n",
    "    def unfreeze(self): self.freeze_to(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, arch, 2, wd=1e-3, callback_fns=[BnFreeze]\n",
    "                    ,dps=[0.01,0.02]\n",
    "                    , opt_fn=partial(optim.SGD, momentum=0.9))\n",
    "learn.metrics = [accuracy]\n",
    "learn.split(lambda m: (m[0][6], m[1]))\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_init(m, init_fn):\n",
    "    if not isinstance(m, bn_types):\n",
    "        if hasattr(m, 'weight'): init_fn(m.weight)\n",
    "        if hasattr(m, 'bias') and hasattr(m.bias, 'data'): m.bias.data.fill_(0.)\n",
    "            \n",
    "def apply_init(m, init_fn):\n",
    "    m.apply(lambda x: cond_init(x, init_fn))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_init(learn.model[1], nn.init.kaiming_normal_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(2, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requires_grad(l):\n",
    "    p = list(l.parameters())\n",
    "    if not p: return None\n",
    "    return p[0].requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradual unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/16, lr/4, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_one_cycle(learn, lrs/2, 12, div_factor=20, pct_end=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv = pd.read_csv(PATH/'default.csv')\n",
    "is_valid = csv['2']=='valid'\n",
    "valid_df,train_df = csv[is_valid],csv[~is_valid]\n",
    "len(valid_df),len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns,train_lbls,valid_fns,valid_lbls = map(np.array,\n",
    "    (train_df['0'],train_df['1'],valid_df['0'],valid_df['1']))\n",
    "\n",
    "train_fns = [PATH/o for o in train_fns]\n",
    "valid_fns = [PATH/o for o in valid_fns]\n",
    "\n",
    "train_ds = FilesDataset(train_fns,train_lbls)\n",
    "valid_ds = FilesDataset(valid_fns,valid_lbls, classes=train_ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
