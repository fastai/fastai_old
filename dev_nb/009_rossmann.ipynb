{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb_008 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rossmann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the feature-engineered filed train_clean and test_clean from the initial data, run nb009a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/rossmann/')\n",
    "train_df = pd.read_feather(PATH/'train_clean')\n",
    "test_df = pd.read_feather(PATH/'test_clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n",
    "    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n",
    "    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n",
    "    'SchoolHoliday_fw', 'SchoolHoliday_bw']\n",
    "\n",
    "contin_vars = ['CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "   'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'SchoolHoliday']\n",
    "\n",
    "n = len(train_df); n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularTransform():\n",
    "    \n",
    "    def __call__(self, df, test=False):\n",
    "        func = self.apply_test if test else self.apply_train\n",
    "        func(df)\n",
    "        \n",
    "    def apply_train(self, df): raise NotImplementedError\n",
    "    def apply_test(self, df):  self.apply_train(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Categorify(TabularTransform):\n",
    "    col_names:Collection[str]\n",
    "    \n",
    "    def apply_train(self, df):\n",
    "        self.categories = {}\n",
    "        for n in self.col_names: \n",
    "            df[n] = df[n].astype('category').cat.as_ordered()\n",
    "            self.categories[n] = df[n].cat.categories\n",
    "            df[n] = df[n].cat.codes\n",
    "    \n",
    "    def apply_test(self, df):\n",
    "        for n in self.col_names:\n",
    "            df[n] = pd.Categorical(df[n], categories=self.categories[n], ordered=True)\n",
    "            df[n] = df[n].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorify = Categorify(cat_vars)\n",
    "categorify(train_df)\n",
    "categorify(test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Retype(TabularTransform):\n",
    "    col_names:Collection[str]\n",
    "    dtypes:Collection[str]\n",
    "    \n",
    "    def __post_init__(self): self.dtypes = listify(self.dtypes, self.col_names)\n",
    "    \n",
    "    def apply_train(self, df):\n",
    "        for n,dt in zip(self.col_names, self.dtypes): df[n] = df[n].astype(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retype = Retype(contin_vars, ['float32'])\n",
    "retype(train_df)\n",
    "retype(test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FillNA(TabularTransform):\n",
    "    col_names:Collection[str]\n",
    "    fill_val:float=0.\n",
    "        \n",
    "    def apply_train(self, df):\n",
    "        for n in self.col_names: df[n] = df[n].fillna(self.fill_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna = FillNA(contin_vars)\n",
    "fillna(train_df)\n",
    "fillna(test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScaleVar(TabularTransform):\n",
    "    col_names:Collection[str]\n",
    "    \n",
    "    def apply_train(self, df):\n",
    "        self.scaler = DataFrameMapper([([n],StandardScaler()) for n in self.col_names])\n",
    "        df[self.scaler.transformed_names_] = self.scaler.fit_transform(df)\n",
    "            \n",
    "    def apply_test(self, df): \n",
    "        df[self.scaler.transformed_names_] = self.scaler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ScaleVar(contin_vars)\n",
    "scaler(train_df)\n",
    "scaler(test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[scaler.scaler.transformed_names_].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FillStrategy = IntEnum('FillStrategy', 'MEDIAN COMMON')\n",
    "\n",
    "@dataclass\n",
    "class FillMissing(TabularTransform):\n",
    "    fill_strategy:FillStrategy=FillStrategy.MEDIAN\n",
    "    add_col:bool=True\n",
    "        \n",
    "    def apply_train(self, df):\n",
    "        self.na_dict = {}\n",
    "        for name,col in df.items():\n",
    "            if pd.isnull(col).sum():\n",
    "                if self.add_col: df[name+'_na'] = pd.isnull(col)\n",
    "                filler = col.median() if self.fill_strategy == FillStrategy.MEDIAN else col.dropna().value_counts().idxmax()\n",
    "                df[name] = col.fillna(filler)\n",
    "                self.na_dict[name] = filler\n",
    "            \n",
    "    def apply_test(self, df): \n",
    "        for name,col in df.items():\n",
    "            if name in self.na_dict:\n",
    "                if self.add_col: df[name+'_na'] = pd.isnull(col)\n",
    "                df[name] = col.fillna(self.na_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing = FillMissing()\n",
    "fill_missing(train_df)\n",
    "fill_missing(test_df, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset():\n",
    "    def __init__(self, df, dep_var, cat_names=None, cont_names=None, log_output=False):\n",
    "        if not is_numeric_dtype(df[dep_var]): df[dep_var] = df[dep_var].cat.codes\n",
    "        self.y = torch.tensor(df[dep_var].values)\n",
    "        if log_output: self.y = torch.log(self.y.float())\n",
    "        df.drop([dep_var], axis=1, inplace=True)\n",
    "        n = len(self.y)\n",
    "        self.cats = np.stack([c.values for n,c in df[cat_names].items()], 1) if cat_names else np.zeros((n,1))\n",
    "        self.cats = LongTensor(self.cats.astype(np.int64))\n",
    "        self.conts = np.stack([c.values for n,c in df[cont_names].items()], 1) if cont_names else np.zeros((n,1))\n",
    "        self.conts = FloatTensor(self.conts.astype(np.float32))\n",
    "    \n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return ((self.cats[idx], self.conts[idx]), self.y[idx])\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframes(cls, train_df, test_df, dep_var, tfms=None, **kwargs):\n",
    "        if tfms is None: tfms = []\n",
    "        for tfm in tfms:\n",
    "            tfm(train_df)\n",
    "            tfm(test_df, test=True)\n",
    "        return cls(train_df, dep_var, **kwargs), cls(test_df, dep_var, **kwargs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_var = 'Sales'\n",
    "train_df = pd.read_feather(PATH/'train_clean')\n",
    "train_df = train_df[cat_vars+contin_vars+[dep_var, 'Date']].copy()\n",
    "train_df = train_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(train_df) * 0.1)\n",
    "train_df,valid_df = train_df[cut:], train_df[:cut]\n",
    "len(train_df),len(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [Categorify(cat_vars), Retype(contin_vars, ['float32']), FillNA(contin_vars), ScaleVar(contin_vars),\n",
    "        FillMissing()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = TabularDataset.from_dataframes(train_df, valid_df, dep_var, tfms, cat_names=cat_vars, \n",
    "                                                    cont_names=contin_vars, log_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(train_ds, valid_ds, bs=64, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
