{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# NLP Preprocessing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": "from fastai.gen_doc.nbdoc import *\nfrom fastai.text import * \nfrom fastai import *"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "The `text.tranform` module contains the function that deal behind the scenes with the two main tasks to prepare texts for the models: tokenization and numericalization.\n\nThe first one consists in splitting the raw texts into tokens (wich can be words, or punctuation signs...). The most basic way to do this would be to separate according to spaces, but it's possible to be more subtle; for instance, the contractions like \"isn't\" or \"don't\" should be split in \\[\"is\",\"n't\"\\] or \\[\"do\",\"n't\"\\].\n\nThe second one is easier as it just consists in attributing a unique id to each token and mapping each of those tokens to their respective ids."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Tokenization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This step is actually divided in two phases: first, we apply a certain list of `rules` to the raw texts as preprocessing, then we use the tokenizer to split them in lists of tokens. Combining together those `rules`, the `tok_func`and the `lang` to process the texts is the role of the [`Tokenizer`](/text.transform.html#Tokenizer) class."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=Tokenizer></a><em>class</em> `Tokenizer`\n`Tokenizer`(<code>tok_func</code>:<code>Callable</code>=`<class 'fastai.text.transform.SpacyTokenizer'>`, <code>lang</code>:<code>str</code>=`'en'`, <code>rules</code>:<code>Collection</code>[<code>Callable</code>[<code>str</code>, <code>str</code>]]=`None`, <code>special_cases</code>:<code>Collection</code>[<code>str</code>]=`None`, <code>n_cpus</code>:<code>int</code>=`None`)\n<a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L82\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Tokenizer, doc_string=False)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This class will process texts by appling them the `rules` then tokenizing them with `tok_func(lang)`. `special_cases` are a list of tokens passed as special to the tokenizer and `n_cpus` is the number of cpus to use for multi-processing (by default, half the cpus available). We don't directly pass a tokenizer for multi-processing purposes: each process needs to initiate a tokenizer of its own."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=process_text></a>`process_text`\n`process_text`(<code>t</code>:<code>str</code>, <code>tok</code>:[<code>BaseTokenizer</code>](/text.transform.html#BaseTokenizer)) -> <code>List</code>[<code>str</code>]\n\n\nProcesse one text `t` with tokenizer `tok`. <a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L96\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Tokenizer.process_text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=process_all></a>`process_all`\n`process_all`(<code>texts</code>:<code>Collection</code>[<code>str</code>]) -> <code>List</code>[<code>List</code>[<code>str</code>]]\n\n\nProcess a list of `texts`. <a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L107\">[source]</a>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Tokenizer.process_all)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Global Variable Definitions:"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`default_rules = [fixup, replace_rep, replace_wrep, deal_caps, spec_add_spaces, rm_useless_spaces, sub_br]` <div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L78\">[source]</a></div>"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`default_spec_tok = [BOS, FLD, UNK, PAD]` <div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L79\">[source]</a></div>"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=BaseTokenizer></a><em>class</em> `BaseTokenizer`(<code>lang</code>:<code>str</code>)<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L11\">[source]</a></div>\n\n\nBasic class for a tokenizer function.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(BaseTokenizer)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`BaseTokenizer`](/text.transform.html#BaseTokenizer)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=add_special_cases></a>`add_special_cases`(<code>toks</code>:<code>Collection</code>[<code>str</code>])<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L17\">[source]</a></div>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(BaseTokenizer.add_special_cases)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`BaseTokenizer.add_special_cases`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=tokenizer></a>`tokenizer`(<code>t</code>:<code>Doc</code>) -> <code>List</code>[<code>str</code>]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L16\">[source]</a></div>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(BaseTokenizer.tokenizer)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`BaseTokenizer.tokenizer`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=SpacyTokenizer></a><em>class</em> `SpacyTokenizer`(<code>lang</code>:<code>str</code>) :: Inherits ([<code>BaseTokenizer</code>](fastai.text.transform.html#BaseTokenizer))<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L20\">[source]</a></div>\n\n\nLittle wrapper around a <code>spacy</code> tokenizer",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(SpacyTokenizer)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`SpacyTokenizer`](/text.transform.html#SpacyTokenizer)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=add_special_cases></a>`add_special_cases`(<code>toks</code>:<code>Collection</code>[<code>str</code>])<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L29\">[source]</a></div>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(SpacyTokenizer.add_special_cases)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`SpacyTokenizer.add_special_cases`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=tokenizer></a>`tokenizer`(<code>t</code>:<code>Doc</code>) -> <code>List</code>[<code>str</code>]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L26\">[source]</a></div>",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(SpacyTokenizer.tokenizer)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`SpacyTokenizer.tokenizer`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=proc_text></a>`proc_text`\n(<code>t</code>:<code>str</code>, <code>tok</code>:[<code>BaseTokenizer</code>](fastai.text.transform.html#BaseTokenizer)) -> <code>List</code>[<code>str</code>]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L95\">[source]</a></div>\n\n\nProcesses one text",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Tokenizer.proc_text)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Tokenizer.proc_text`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=process_all></a>`process_all`\n(<code>texts</code>:<code>Collection</code>[<code>str</code>]) -> <code>List</code>[<code>List</code>[<code>str</code>]]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L106\">[source]</a></div>\n\n\nProcesses a list of texts in several processes",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Tokenizer.process_all)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Tokenizer.process_all`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=process_all_1></a>`process_all_1`\n(<code>texts</code>:<code>Collection</code>[<code>str</code>]) -> <code>List</code>[<code>List</code>[<code>str</code>]]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L100\">[source]</a></div>\n\n\nProcesses a list of texts in one process",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Tokenizer.process_all_1)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Tokenizer.process_all_1`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "### <a id=Vocab></a><em>class</em> `Vocab`(<code>path</code>:<code>None</code>[<code>Path</code>, <code>str</code>])<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L112\">[source]</a></div>\n\n\nContains the correspondance between numbers and tokens and numericalizes",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Vocab)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`Vocab`](/text.transform.html#Vocab)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=create></a>`create`\n(<code>path</code>:<code>None</code>[<code>Path</code>, <code>str</code>], <code>tokens</code>:<code>Collection</code>[<code>Collection</code>[<code>str</code>]], <code>max_vocab</code>:<code>int</code>, <code>min_freq</code>:<code>int</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L127\">[source]</a></div>\n\n\nCreate a vocabulary from a set of tokens.",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Vocab.create)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Vocab.create`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=numericalize></a>`numericalize`\n(<code>t</code>:<code>Collection</code>[<code>str</code>]) -> <code>List</code>[<code>int</code>]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L119\">[source]</a></div>\n\n\nConverts a list of tokens to their ids",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Vocab.numericalize)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Vocab.numericalize`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=textify></a>`textify`\n(<code>nums</code>:<code>Collection</code>[<code>int</code>]) -> <code>List</code>[<code>str</code>]<div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L123\">[source]</a></div>\n\n\nConverts a list of ids to their tokens",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(Vocab.textify)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "`Vocab.textify`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=deal_caps></a>`deal_caps`(<code>t</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L62\">[source]</a></div>\n\n\nReplace words in all caps",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(deal_caps)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`deal_caps`](/text.transform.html#deal_caps)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=fixup></a>`fixup`(<code>x</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L69\">[source]</a></div>\n\n\nList of replacements from html strings",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(fixup)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`fixup`](/text.transform.html#fixup)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=replace_rep></a>`replace_rep`(<code>t</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L46\">[source]</a></div>\n\n\nReplace repetitions at the character level",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(replace_rep)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`replace_rep`](/text.transform.html#replace_rep)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=replace_wrep></a>`replace_wrep`(<code>t</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L54\">[source]</a></div>\n\n\nReplace word repetitions",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(replace_wrep)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`replace_wrep`](/text.transform.html#replace_wrep)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=rm_useless_spaces></a>`rm_useless_spaces`(<code>t</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L42\">[source]</a></div>\n\n\nRemove multiple spaces",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(rm_useless_spaces)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`rm_useless_spaces`](/text.transform.html#rm_useless_spaces)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=spec_add_spaces></a>`spec_add_spaces`(<code>t</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L38\">[source]</a></div>\n\n\nAdd spaces between special characters",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(spec_add_spaces)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`spec_add_spaces`](/text.transform.html#spec_add_spaces)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": "#### <a id=sub_br></a>`sub_br`(<code>t</code>:<code>str</code>) -> <code>str</code><div style=\"text-align: right\"><a href=\"https://github.com/fastai/fastai_pytorch/blob/master/fastai/text/transform.py#L33\">[source]</a></div>\n\n\nReplaces the <br /> by",
      "text/plain": "<IPython.core.display.Markdown object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": "show_doc(sub_br)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[`sub_br`](/text.transform.html#sub_br)"
  }
 ],
 "metadata": {
  "jekyll": {
   "summary": "Module helps with formatting NLP data. Tokenizes text and creates vocab indexes",
   "title": "text.transform"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
