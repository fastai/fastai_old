{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`basic_train` wraps together the data (in a [<code>DataBunch</code>](http://docs.fast.ai/data.html#DataBunch) object) with a pytorch model to define a [<code>Learner</code>](http://docs.fast.ai/basic_train.html#Learner) object. This is where the basic training loop is defined in the [<code>fit</code>](http://docs.fast.ai/basic_train.html#fit) function. The [<code>Learner</code>](http://docs.fast.ai/basic_train.html#Learner) object is the entry point of most of the [<code>Callback</code>](http://docs.fast.ai/callback.html#Callback) functions that will customize this training loop in different ways, notably:\n",
    "\n",
    " - `Learner.lr_find` will launch an LR range test that will help you select a good learning rate\n",
    " - `Learner.fit_one_cycle` will launch a training using the 1cycle policy, to help you train your model fast.\n",
    " - `Learner.to_fp16` will convert your model in half precision and halp you launch a training in mixed precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.basic_train import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variable Definitions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`default_lr = slice(3e-3)` <div style=\"text-align: right\"><a href=\"../fastai/basic_train.py#L11\">[source]</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`default_wd = 1e-2` <div style=\"text-align: right\"><a href=\"../fastai/basic_train.py#L12\">[source]</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=fit></a>**fit**(<em>epochs</em>=int, <em>model</em>=torch.nn.modules.module.Module, <em>loss_fn</em>: torch.Tensor],=Callable[[torch.Tensor,, <em>opt</em>=torch.optim.optimizer.Optimizer, <em>data</em>=fastai.data.DataBunch, <em>callbacks</em>: NoneType]=Union[Collection[fastai.callback.Callback],, <em>metrics</em>: numbers.Number]],=Union[Collection[Union[torch.Tensor,)\n",
       "\n",
       "\n",
       "Fit the `model` on `data` and learn using `loss` and `opt`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>fit</code>](http://docs.fast.ai/basic_train.html#fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### <a id=Learner></a><em>class</em> **Learner**(<em>model</em>=torch.nn.modules.module.Module, <em>opt_fn</em>: functools.partial(<class=Callable, <em>loss_fn</em>: <function=Callable, <em>metrics</em>: None=Collection[Callable], <em>true_wd</em>: True=bool, <em>bn_wd</em>: True=bool, <em>wd</em>: Collection[float]]=Union[float,, <em>train_bn</em>: True=bool, <em>path</em>: None=str, <em>model_dir</em>: 'models'=str, <em>callback_fns</em>: None=Collection[Callable], <em>callbacks</em>: <factory>=Collection[fastai.callback.Callback], <em>layer_groups</em>: None=Collection[torch.nn.modules.module.Module])\n",
       "\n",
       "\n",
       "Object that wraps together some data, a model, a loss function and an optimizer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>Learner</code>](http://docs.fast.ai/basic_train.html#Learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=create_opt></a>**create_opt**(<em>self</em>, <em>lr</em>: Collection[float]]=Union[float,, <em>wd</em>: Collection[float]]=Union[float,)\n",
       "\n",
       "\n",
       "create optimizer with `lr` learning rate and `wd` weight decay"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.create_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.create_opt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=fit></a>**fit**(<em>self</em>, <em>epochs</em>=int, <em>lr</em>: Collection[float],=Union[float,, <em>wd</em>: Collection[float]]=Union[float,, <em>callbacks</em>: None=Collection[fastai.callback.Callback])\n",
       "\n",
       "\n",
       "fit the model on this learner with `lr` learning rate, `wd` weight decay for `epochs` with `callbacks`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=fit_one_cycle></a>**fit_one_cycle**(<em>learn</em>, <em>cyc_len</em>=fastai.basic_train.Learner, <em>max_lr</em>: Collection[float],=int, <em>moms</em>: float]=Union[float,, <em>div_factor</em>: 25.0=Tuple[float,, <em>pct_start</em>: 0.3=float, <em>wd</em>: None=float, <em>**kwargs</em>=float)\n",
       "\n",
       "\n",
       "Fits a model following the 1cycle policy"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.fit_one_cycle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.fit_one_cycle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=freeze></a>**freeze**(<em>self</em>)\n",
       "\n",
       "\n",
       "freeze up to last layer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.freeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.freeze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=freeze_to></a>**freeze_to**(<em>self</em>, <em>n</em>=int)\n",
       "\n",
       "\n",
       "freeze layers up to layer `n`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.freeze_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.freeze_to`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=_learn_get_preds></a>**_learn_get_preds**(<em>learn</em>=fastai.basic_train.Learner, <em>is_test</em>: False=bool)\n",
       "\n",
       "\n",
       "Wrapper of get_preds for learner"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.get_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.get_preds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=init></a>**init**(<em>self</em>, <em>init</em>)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.init`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=load></a>**load**(<em>self</em>, <em>name</em>: str]=Union[pathlib.Path,)\n",
       "\n",
       "\n",
       "load model `name` from `self.model_dir"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.load`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=cross_entropy></a>**cross_entropy**(<em>input</em>, <em>target</em>, <em>weight</em>=None, <em>size_average</em>=None, <em>ignore_index</em>=-100, <em>reduce</em>=None, <em>reduction</em>='elementwise_mean')\n",
       "\n",
       "\n",
       "function.\n",
       "\n",
       "See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
       "\n",
       "Args:\n",
       "    input (Tensor) : :math:`(N, C)` where `C = number of classes` or :math:`(N, C, H, W)`\n",
       "        in case of 2D Loss, or :math:`(N, C, d_1, d_2, ..., d_K)` where :math:`K > 1`\n",
       "        in the case of K-dimensional loss.\n",
       "    target (Tensor) : :math:`(N)` where each value is :math:`0 \\leq \\text{targets}[i] \\leq C-1`,\n",
       "        or :math:`(N, d_1, d_2, ..., d_K)` where :math:`K \\geq 1` for\n",
       "        K-dimensional loss.\n",
       "    weight (Tensor, optional): a manual rescaling weight given to each\n",
       "        class. If given, has to be a Tensor of size `C`\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when reduce is ``False``. Default: ``True``\n",
       "    ignore_index (int, optional): Specifies a target value that is ignored\n",
       "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
       "        ``True``, the loss is averaged over non-ignored targets. Default: -100\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (string, optional): Specifies the reduction to apply to the output:\n",
       "        'none' | 'elementwise_mean' | 'sum'. 'none': no reduction will be applied,\n",
       "        'elementwise_mean': the sum of the output will be divided by the number of\n",
       "        elements in the output, 'sum': the output will be summed. Note: :attr:`size_average`\n",
       "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
       "        specifying either of those two args will override :attr:`reduction`. Default: 'elementwise_mean'\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
       "    >>> loss = F.cross_entropy(input, target)\n",
       "    >>> loss.backward()"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.loss_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=lr_find></a>**lr_find**(<em>learn</em>=fastai.basic_train.Learner, <em>start_lr</em>: 1e-05=float, <em>end_lr</em>: 10=float, <em>num_it</em>: 100=int, <em>**kwargs</em>=Any)\n",
       "\n",
       "\n",
       "Explore lr from `start_lr` to `end_lr` over `num_it` iterations of `learn`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.lr_find)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.lr_find`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=lr_range></a>**lr_range**(<em>self</em>, <em>lr</em>: slice]=Union[float,)\n",
       "\n",
       "\n",
       "Build learning rate schedule"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.lr_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.lr_range`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=mixup></a>**mixup**(<em>learn</em>=fastai.basic_train.Learner, <em>alpha</em>: 0.4=float, <em>stack_x</em>: False=bool, <em>stack_y</em>: True=bool)\n",
       "\n",
       "\n",
       "Adds mixup https://arxiv.org/abs/1710.09412 to the learner"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.mixup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.mixup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=pred_batch></a>**pred_batch**(<em>learn</em>=fastai.basic_train.Learner, <em>is_valid</em>: True=bool)\n",
       "\n",
       "\n",
       "Returns input, target and output of the model on a batch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.pred_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.pred_batch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=save></a>**save**(<em>self</em>, <em>name</em>: str]=Union[pathlib.Path,)\n",
       "\n",
       "\n",
       "save model with `name` to `self.model_dir`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.save`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=split></a>**split**(<em>self</em>, <em>split_on</em>: Collection[Collection[torch.nn.modules.module.Module]]]=Union[Callable,)\n",
       "\n",
       "\n",
       "split the model at `split_on`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=to_fp16></a>**to_fp16**(<em>learn</em>=fastai.basic_train.Learner, <em>loss_scale</em>: 512.0=float, <em>flat_master</em>: False=bool)\n",
       "\n",
       "\n",
       "Transforms the learner in FP16 precision"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.to_fp16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.to_fp16`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=_TTA></a>**_TTA**(<em>learn</em>=fastai.basic_train.Learner, <em>beta</em>: 0.4=float, <em>scale</em>: 1.35=float, <em>is_test</em>: False=bool)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.TTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.TTA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=_tta_only></a>**_tta_only**(<em>learn</em>=fastai.basic_train.Learner, <em>is_test</em>: False=bool, <em>scale</em>: 1.25=float)\n",
       "\n",
       "\n",
       "Computes the outputs for several augmented inputs for TTA"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.tta_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.tta_only`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=unfreeze></a>**unfreeze**(<em>self</em>)\n",
       "\n",
       "\n",
       "unfreeze entire model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.unfreeze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Learner.unfreeze`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### <a id=LearnerCallback></a><em>class</em> **LearnerCallback**() :: Inherits from (`Callback`)\n",
       "\n",
       "\n",
       "Base class for creating callbacks for the `Learner`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LearnerCallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>LearnerCallback</code>](http://docs.fast.ai/basic_train.html#LearnerCallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=loss_batch></a>**loss_batch**(<em>model</em>=torch.nn.modules.module.Module, <em>xb</em>=torch.Tensor, <em>yb</em>=torch.Tensor, <em>loss_fn</em>: torch.Tensor],=Union[Callable[[torch.Tensor,, <em>opt</em>: NoneType]=Union[torch.optim.optimizer.Optimizer,, <em>cb_handler</em>: NoneType]=Union[fastai.callback.CallbackHandler,, <em>metrics</em>: numbers.Number]],=Union[Collection[Union[torch.Tensor,)\n",
       "\n",
       "\n",
       "Calculate loss for a batch, calculate metrics, call out to callbacks as necessary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(loss_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>loss_batch</code>](http://docs.fast.ai/basic_train.html#loss_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### <a id=Recorder></a><em>class</em> **Recorder**() :: Inherits from (`LearnerCallback`)\n",
       "\n",
       "\n",
       "A `LearnerCallback` that records epoch,loss,opt and metric data during training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>Recorder</code>](http://docs.fast.ai/basic_train.html#Recorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=format_stats></a>**format_stats**(<em>self</em>, <em>stats</em>: numbers.Number]]=Collection[Union[torch.Tensor,)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.format_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.format_stats`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=on_backward_begin></a>**on_backward_begin**(<em>self</em>, <em>smooth_loss</em>=torch.Tensor, <em>**kwargs</em>=Any)\n",
       "\n",
       "\n",
       "Record the loss before any other callback has a chance to modify it."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.on_backward_begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.on_backward_begin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=on_batch_begin></a>**on_batch_begin**(<em>self</em>, <em>**kwargs</em>=Any)\n",
       "\n",
       "\n",
       "Record learning rate and momentum at beginning of batch"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.on_batch_begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.on_batch_begin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=on_epoch_end></a>**on_epoch_end**(<em>self</em>, <em>epoch</em>=int, <em>num_batch</em>=int, <em>smooth_loss</em>=torch.Tensor, <em>last_metrics</em>: numbers.Number]]=typing.Collection[typing.Union[torch.Tensor,, <em>**kwargs</em>=Any)\n",
       "\n",
       "\n",
       "Save epoch info: num_batch, smooth_loss, metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.on_epoch_end`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=on_train_begin></a>**on_train_begin**(<em>self</em>, <em>pbar</em>: fastprogress.fastprogress.ProgressBar]=Union[fastprogress.fastprogress.MasterBar,, <em>metrics</em>: torch.Tensor],=Collection[Callable[[torch.Tensor,, <em>**kwargs</em>=Any)\n",
       "\n",
       "\n",
       "Initialize recording status at beginning of training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.on_train_begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.on_train_begin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=plot></a>**plot**(<em>self</em>, <em>skip_start</em>: 10=int, <em>skip_end</em>: 5=int)\n",
       "\n",
       "\n",
       "Plot learning rate and losses, trimmed between `skip_start` and `skip_end`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.plot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=plot_losses></a>**plot_losses**(<em>self</em>)\n",
       "\n",
       "\n",
       "Plot training and validation losses"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.plot_losses`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=plot_lr></a>**plot_lr**(<em>self</em>, <em>show_moms</em>=False)\n",
       "\n",
       "\n",
       "Plot learning rate, `show_moms` to include momentum"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.plot_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.plot_lr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=plot_metrics></a>**plot_metrics**(<em>self</em>)\n",
       "\n",
       "\n",
       "Plot metrics collected during training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Recorder.plot_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recorder.plot_metrics`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=train_epoch></a>**train_epoch**(<em>model</em>=torch.nn.modules.module.Module, <em>dl</em>=torch.utils.data.dataloader.DataLoader, <em>opt</em>=torch.optim.optimizer.Optimizer, <em>loss_func</em>: torch.Tensor],=Callable[[torch.Tensor,)\n",
       "\n",
       "\n",
       "Simple training of `model` for 1 epoch of `dl` using optim `opt` and loss function `loss_func`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>train_epoch</code>](http://docs.fast.ai/basic_train.html#train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### <a id=validate></a>**validate**(<em>model</em>=torch.nn.modules.module.Module, <em>dl</em>=torch.utils.data.dataloader.DataLoader, <em>loss_fn</em>: torch.Tensor],=Union[Callable[[torch.Tensor,, <em>metrics</em>: numbers.Number]],=Union[Collection[Union[torch.Tensor,, <em>cb_handler</em>: NoneType]=Union[fastai.callback.CallbackHandler,, <em>pbar</em>: fastprogress.fastprogress.ProgressBar,=Union[fastprogress.fastprogress.MasterBar,)\n",
       "\n",
       "\n",
       "Calculate loss and metrics for the validation set"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<code>validate</code>](http://docs.fast.ai/basic_train.html#validate)"
   ]
  }
 ],
 "metadata": {
  "jekyll": {
   "summary": "Provides basic training and validation with `Learner`",
   "title": "basic_train"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
